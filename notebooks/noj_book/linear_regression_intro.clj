;; # Intro to Linear Regression - DRAFT ðŸ› 

;; **last update:** 2024-12-29

;; Here we offer an intro to [linear regression](https://en.wikipedia.org/wiki/Linear_regression)
;; following the
;; [In Depth: Linear Regression](https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html)
;; section of the
;; [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/)
;; by Jake VanderPlas.

;; ## Setup

(ns noj-book.linear-regression-intro
  (:require
   [tech.v3.dataset :as ds]
   [tablecloth.api :as tc]
   [tablecloth.column.api :as tcc]
   [tech.v3.datatype.datetime :as datetime]
   [tech.v3.dataset.modelling :as ds-mod]
   [fastmath.ml.regression :as reg]
   [scicloj.kindly.v4.kind :as kind]
   [fastmath.random :as rand]
   [scicloj.tableplot.v1.plotly :as plotly]))

;; ## Simple Linear Regrssion

;; Let us start with the basic model of a straight-line fit, where points $(x,y)$ are
;; assumed to have a relationship where $y$ can be predicted as $$y=ax+b.$$
;; Here, $a$ is the slope of the line, and $b$ is the so-called intercept, the height of
;; crossing the $y$ axis.

;; To explore this kind of relationship, we will use
;; Fastmath and Tablecloth to
;; generate random data where it holds for $a=2$ and $b=-5$.

;; For each row of the dataset below, we pick $x$ as a uniform
;; random number between 0 to 10, and we compute $y$ as
;; $ax+b$ plus additional standard Gaussian random error
;; (Normally distributed with mean 0 and variance 1),
;; independently of all other rows.

(def simple-linear-data
  (let [rng (rand/rng 1234)
        n 50
        a 2
        b -5]
    (-> {:x (repeatedly n #(rand/frandom rng 0 10))}
        tc/dataset
        (tc/map-columns :y
                        [:x]
                        (fn [x]
                          (+ (* a x)
                             b
                             (rand/grandom rng)))))))

simple-linear-data

;; Let us plot the data using Tableplot's Plotly API.

(-> simple-linear-data
    plotly/layer-point)

;; ### Regression using Fastmath

;; To estimate a linear relationship, we may use the Fastmath library.

(def simple-linear-data-model
  (reg/lm
   ;; ys - a "column" sequence of `y` values:
   (simple-linear-data :y)
   ;; xss - a sequence of "rows", each containing `x` values
   ;; (one `x` per row, in our case):
   (-> simple-linear-data
       (tc/select-columns [:x])
       tc/rows)
   ;; options
   {:names ["x"]}))

(type simple-linear-data-model)

simple-linear-data-model

;; When the fit model is printed, we get a nice tabular summary.
;; Let us capture the printed value and display it here.
;; Using [Kindly](https://scicloj.github.io/kindly/),
;; we mark it as `kind/code` for convenient rendering.

(kind/code
 (with-out-str
   (println
    simple-linear-data-model)))

;; We can see the regression could estimate the intercept $b$ and
;; the slope $a$ (the coefficient of $x$).

;; ### Dataset ergonomics

;; Let us write a couple of convenience functions
;; that will help us use regression with datasets and view
;; the summary with Kindly.
;; We are working on similar functionality in the
;; [Tablemath](https://scicloj.github.io/tablemath) library,
;; which is still in experimental stage and is thus not included
;; in Noj yet.

(defn lm
  "Compute a linear regression model for `dataset`.
  The first column marked as target is the target.
  All the columns unmarked as target are the features.
  The resulting model is of type `fastmath.ml.regression.LMData`,
  a generated by [Fastmath](https://github.com/generateme/fastmath).
  
  See [fastmath.ml.regression.lm](https://generateme.github.io/fastmath/clay/ml.html#lm)
  for `options`."

  ([dataset]
   (lm dataset nil))
  ([dataset options]
   (let [inference-column-name (-> dataset
                                   ds-mod/inference-target-column-names
                                   first)
         ds-without-target (-> dataset
                               (tc/drop-columns [inference-column-name]))]
     (reg/lm
      ;; ys
      (get dataset inference-column-name)
      ;; xss
      (tc/rows ds-without-target)
      ;; options
      (merge {:names (-> ds-without-target
                         tc/column-names
                         vec)}
             options)))))

(defn summary
  "Generate a summary of a linear model."
  [lmdata]
  (kind/code
   (with-out-str
     (println
      lmdata))))

(-> simple-linear-data
    (ds-mod/set-inference-target :y)
    lm
    summary)

;; ### Prediction

;; Given a linear model, we can ask it for new predictions.

;; Here is the prediction for $x=3$:

(simple-linear-data-model [3])

;; ### Displaying the regression line

;; We can use Tableplot to visualize the regression model
;; as and additional layer.
;; Behind the scenes, it uses Fastmath `lm` by default, so
;; the result should be compatibile.

(-> simple-linear-data
    plotly/layer-point
    plotly/layer-smooth)

;; We could also generate this explicitly ourselves:

(-> simple-linear-data
    (tc/map-columns :prediction
                    [:x]
                    simple-linear-data-model)
    plotly/layer-point
    (plotly/layer-smooth {:=y :prediction}))

;; ## Multiple linear regression

;; Linear dependency on a few variables can be estimatd the same way.

(def multiple-linear-data
  (let [rng (rand/rng 1234)
        n 50
        a0 2
        a1 -3
        b -5]
    (-> {:x0 (repeatedly n #(rand/frandom rng 0 10))
         :x1 (repeatedly n #(rand/frandom rng 0 10))}
        tc/dataset
        (tc/map-columns :y
                        [:x0 :x1]
                        (fn [x0 x1]
                          (+ (* a0 x0)
                             (* a1 x1)
                             b
                             (rand/grandom rng)))))))

(def multiple-linear-data-model
  (-> multiple-linear-data
      (ds-mod/set-inference-target :y)
      lm))

(summary multiple-linear-data-model)

;; Visualization is different, of course.
;; Here, we use a combination of Tableplot's Plotly API
;; and Plotly's own specification.
;; We are planning to improve Tableplot so that
;; such details will be handled more directly
;; as layers in its API. ðŸ› 

(-> multiple-linear-data
    (plotly/layer-point {:=coordinates :3d
                         :=x :x0
                         :=y :x1
                         :=z :y}) 
    plotly/plot
    (assoc-in [:data 1]
              {:type :surface
               :z (for [i (range 11)]
                    (for [j (range 11)]
                      (multiple-linear-data-model
                       [j i])))
               :opacity 0.5}))

;; ## Coming soon: Polynomial regression ðŸ› 

;; ## Coming soon: One-hot encoding ðŸ› 

;; ## Coming soon: Regularization ðŸ› 


;; ## Example: Predicting Bicycle Traffic

;; Following the Python Data Science Handbook, we will look into predicting
;; the daily number of bicycle trips across Fremob Bridge in Seattle.
;; We can use the information of weather, season, day of week, etc.

;; ### Reading and parsing data

(def column-name-mapping
  {"Fremont Bridge Sidewalks, south of N 34th St" :total
   "Fremont Bridge Sidewalks, south of N 34th St Cyclist West Sidewalk" :west
   "Fremont Bridge Sidewalks, south of N 34th St Cyclist East Sidewalk" :east
   "Date" :datetime})

(column-name-mapping
 "Fremont Bridge Sidewalks, south of N 34th St")

(def counts
  (tc/dataset "data/seattle-bikes-and-weather/Fremont_Bridge_Bicycle_Counter.csv.gz"
              {:key-fn column-name-mapping
               :parser-fn {"Date" [:local-date-time "MM/dd/yyyy hh:mm:ss a"]}}))

counts

(def weather
  (tc/dataset "data/seattle-bikes-and-weather/BicycleWeather.csv.gz"
              {:key-fn keyword}))

weather

;; ### Preprocessing

;; Our bike counts data are hourly, but the weather data is daily.
;; To join them, we will need to convert the bike hourly counts to daily counts.

;; In the Python book, this is done as follows in Pandas:
;; ```python
;; daily = counts.resample('d').sum()
;; ```

;; Tablecloth's full support for time series is still under construction.
;; For now, we will have to be a bit more verbose:

(def daily-totals
  (-> counts
      (tc/group-by (fn [{:keys [datetime]}]
                     {:date (datetime/local-date-time->local-date
                             datetime)}))
      (tc/aggregate-columns [:total :west :east]
                            tcc/sum)))


daily-totals

;; ### Prediction by day-of-week

;; Let us prepare the data for regression on the day of week.

(def days-of-week
  [:Mon :Tue :Wed :Thu :Fri :Sat :Sun])


;; We will convert numbers to days-of-week keywords:

(def idx->day-of-week
  (comp days-of-week dec))

;; E.g., 
(idx->day-of-week 1)
(idx->day-of-week 7)

;; Now, let us prepare the data:

(def totals-with-day-of-week
  (-> daily-totals
      (tc/add-column :day-of-week
                     (fn [ds]
                       (map idx->day-of-week
                            (datetime/long-temporal-field
                             :day-of-week
                             (:date ds)))))
      (tc/select-columns [:total :day-of-week])))

totals-with-day-of-week

(def totals-with-one-hot-days-of-week
  (-> (reduce (fn [dataset day-of-week]
                (-> dataset
                    (tc/add-column day-of-week
                                   #(-> (:day-of-week %)
                                        (tcc/eq day-of-week)
                                        ;; turn booleans into 0s and 1s
                                        (tcc/* 1)))))
              totals-with-day-of-week
              days-of-week)
      (tc/drop-columns [:day-of-week])
      (ds-mod/set-inference-target :total)))

(-> totals-with-one-hot-days-of-week
    (tc/select-columns ds-mod/inference-column?))

;; The binary columns are collinear (sum up to 1),
;; but we will avoide the intercept.
;; This way, the interpretation of each coefficient is the expected
;; bike count for the corresponding day of week.

(def days-of-week-model
  (lm totals-with-one-hot-days-of-week
      {:intercept? false}))

;; Here are the regression results:

(-> days-of-week-model
    println
    with-out-str
    kind/code)

;; We can see the difference between weekends and weekdays.

;; ### Coming soon: more predictors for the bike counts ðŸ› 

